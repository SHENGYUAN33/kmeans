import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# from cuml.cluster import KMeans  # GPU åŠ é€Ÿç‰ˆ
from sklearn.cluster import KMeans  # CPUç‰ˆ
from sklearn.preprocessing import StandardScaler
from math import ceil
import argparse
from tqdm import tqdm
import torch
import torchvision.models as models
import torchvision.transforms as transforms
import umap
from math import ceil
import joblib  # å„²å­˜kemeansæ¨¡å‹


print("ğŸš€ CUDA æ˜¯å¦å¯ç”¨:", torch.cuda.is_available())
print("ğŸ–¥ï¸ ä½¿ç”¨çš„ GPU:", torch.cuda.get_device_name(
    0) if torch.cuda.is_available() else "None")


# å‘½ä»¤åˆ—åƒæ•¸è¨­å®š
parser = argparse.ArgumentParser()
parser.add_argument('--image_dir', type=str,
                    default=r"H:\\dino\\new_clusters", help='åœ–ç‰‡è³‡æ–™å¤¾è·¯å¾‘')
parser.add_argument('--n_clusters', type=int, default=6, help='KMeans åˆ†ç¾¤æ•¸é‡')
parser.add_argument('--output_dir', type=str,
                    default='cluster_outputs', help='ç¸®åœ–è¼¸å‡ºè³‡æ–™å¤¾')

args = parser.parse_args()

image_dir = args.image_dir
n_clusters = args.n_clusters
output_dir = args.output_dir
os.makedirs(output_dir, exist_ok=True)

# åˆå§‹åŒ– ResNet18 æ¨¡å‹ä½œç‚ºåµŒå…¥å™¨
resnet = models.resnet18(pretrained=True)
resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # å»æ‰åˆ†é¡å±¤
resnet.eval()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
resnet.to(device)

transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ç‰¹å¾µæ“·å–å‡½æ•¸


def extract_features(img_path):
    img = cv2.imread(img_path)
    if img is None:
        return None

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # æ·±åº¦å­¸ç¿’åµŒå…¥ç‰¹å¾µ
    input_tensor = transform(img_rgb).unsqueeze(0).to(device)
    with torch.no_grad():
        embedding = resnet(input_tensor).cpu().numpy().flatten()

    features = {
        'mean_R': np.mean(img_rgb[:, :, 0]),
        'mean_G': np.mean(img_rgb[:, :, 1]),
        'mean_B': np.mean(img_rgb[:, :, 2]),
        'std_R': np.std(img_rgb[:, :, 0]),
        'std_G': np.std(img_rgb[:, :, 1]),
        'std_B': np.std(img_rgb[:, :, 2]),
        'mean_H': np.mean(img_hsv[:, :, 0]),
        'mean_S': np.mean(img_hsv[:, :, 1]),
        'mean_V': np.mean(img_hsv[:, :, 2]),
        'mean_gray': np.mean(img_gray),
        'std_gray': np.std(img_gray),
        'blur_score': cv2.Laplacian(img_gray, cv2.CV_64F).var(),
        'color_temp': np.mean(img_rgb[:, :, 0]) - np.mean(img_rgb[:, :, 2])
    }

    for i, val in enumerate(embedding):
        features[f'emb_{i}'] = val

    return features


# æ“·å–æ‰€æœ‰åœ–ç‰‡ç‰¹å¾µ
features_list = []
file_paths = []

for file in tqdm(os.listdir(image_dir), desc="æ“·å–å½±åƒç‰¹å¾µ"):
    if file.lower().endswith('.bmp'):
        full_path = os.path.join(image_dir, file)
        features = extract_features(full_path)
        if features:
            features_list.append(features)
            file_paths.append(full_path)

# Find best k using silhouette score


def find_best_k_silhouette(X_scaled, k_min=2, k_max=10):
    best_k = k_min
    best_score = -1
    for k in range(k_min, k_max + 1):
        kmeans = KMeans(n_clusters=k, random_state=42).fit(X_scaled)
        score = silhouette_score(X_scaled, kmeans.labels_)
        print(f"k={k} â†’ Silhouette Score: {score:.4f}")
        if score > best_score:
            best_score = score
            best_k = k
    return best_k


best_k = find_best_k_silhouette(X_scaled, k_min=2, k_max=max_k)
print(f"âœ… ä½¿ç”¨æœ€ä½³ç¾¤æ•¸ï¼š{best_k}")

# å»ºç«‹ DataFrame ä¸¦æ¨™æº–åŒ–
df_feat = pd.DataFrame(features_list)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df_feat)

# åŸ·è¡Œ GPU åŠ é€Ÿç‰ˆ KMeans èšé¡
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
labels = kmeans.fit_predict(X_scaled)
df_feat['filepath'] = file_paths
df_feat['cluster'] = labels

# ä½¿ç”¨ UMAP é™ç¶­å¾Œç¹ªåœ–
reducer = umap.UMAP(n_components=2, random_state=42)
umap_result = reducer.fit_transform(X_scaled)

# å„²å­˜æ¨¡å‹
joblib.dump(kmeans, os.path.join(output_dir, "kmeans_model.pkl"))
print("âœ… å·²å„²å­˜ KMeans æ¨¡å‹è‡³ kmeans_model.pkl")

df_feat['umap_x'] = umap_result[:, 0]
df_feat['umap_y'] = umap_result[:, 1]

plt.figure(figsize=(10, 6))
for c in range(n_clusters):
    subset = df_feat[df_feat['cluster'] == c]
    plt.scatter(subset['umap_x'], subset['umap_y'],
                label=f'Cluster {c}', alpha=0.6)
plt.legend()
plt.title("UMAP Clustering Visualization")
plt.savefig(os.path.join(output_dir, "umap_clusters.png"))
plt.close()

# é¡¯ç¤ºæ¯ç¾¤çš„ç¸®åœ–ç‰†ä¸¦è‡ªå‹•å„²å­˜


def plot_cluster_thumbnails(df, cluster_num, output_dir="cluster_thumbnails", images_per_row=6, max_images=100):
    os.makedirs(output_dir, exist_ok=True)

    files = df[df['cluster'] == cluster_num]['filepath'].tolist()
    count = min(len(files), max_images)  # é™åˆ¶æœ€å¤šé¡¯ç¤º max_images å¼µåœ–
    rows = ceil(count / images_per_row)

    fig, axes = plt.subplots(rows, images_per_row, figsize=(
        images_per_row * 2.5, rows * 2.5))
    axes = axes.flatten()

    for i in range(len(axes)):
        if i < count:
            img = cv2.imread(files[i])
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            axes[i].imshow(img)
            axes[i].axis('off')
        else:
            axes[i].remove()

    fig.suptitle(f'Cluster {cluster_num}', fontsize=16)
    plt.tight_layout(rect=[0, 0, 1, 0.95])  # ç•™ç©ºé–“çµ¦æ¨™é¡Œ

    out_path = os.path.join(output_dir, f'cluster_{cluster_num}.png')
    plt.savefig(out_path, dpi=100)
    plt.close()


# ç¹ªè£½æ‰€æœ‰ç¾¤çµ„çµæœ
for cluster_id in tqdm(sorted(df_feat['cluster'].unique()), desc="å„²å­˜å„ç¾¤ç¸®åœ–"):
    plot_cluster_thumbnails(df_feat, cluster_id)

# åŒ¯å‡ºç¾¤çµ„çµæœè‡³ CSV
csv_path = os.path.join(output_dir, "cluster_results_with_all_features.csv")
df_feat.to_csv(csv_path, index=False)
print(f"\nâœ… èšé¡å®Œæˆï¼Œçµæœå·²å„²å­˜è‡³ {csv_path} å’Œ {output_dir} è³‡æ–™å¤¾")
